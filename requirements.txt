# Core deep learning
torch>=2.0.0
torchvision>=0.15.0

# Image and video processing
opencv-python>=4.8.0
pillow>=10.0.0
scikit-image>=0.21.0

# Numerical and scientific computing
numpy>=1.24.0
scipy>=1.11.0
scikit-learn>=1.3.0

# CLIP model (for encoder_backend="clip")
git+https://github.com/openai/CLIP.git

# DINOv3/DINOv2 model support (for encoder_backend="dinov3")
# Uses Hugging Face Transformers with safe loading (no trust_remote_code)
transformers>=4.35.0
safetensors>=0.4.0

# DPP sampling
dppy>=0.3.2

# GPU-accelerated K-means (optional, for selector.kmeans_use_gpu)
torch-kmeans>=0.2.0

# Progress bars and utilities
tqdm>=4.66.0

# Configuration
pyyaml>=6.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Optional: for GPU video decoding (uncomment to enable)
decord>=0.6.0

# Optional: GPU HDBSCAN via RAPIDS (requires separate conda install)
# cuml  # Install via conda: conda install -c rapidsai cuml

# Optional: for RAFT optical flow
# torchvision handles this, but for standalone RAFT:
einops>=0.6.0
